{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPYLmC1vOOBF"
      },
      "source": [
        "# CIFAR10 Federated Mobilenet Server Side\n",
        "This code is the server part of CIFAR10 federated mobilenet for **multi** client and a server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqsEm6bUOOBJ"
      },
      "source": [
        "## Setting variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CHXlfVPIOOBK"
      },
      "outputs": [],
      "source": [
        "# \n",
        "rounds = 100\n",
        "local_epoch = 1\n",
        "users = 1 # number of clients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPVU4OIOOOBM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "\n",
        "import socket\n",
        "import struct\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from threading import Thread\n",
        "from threading import Lock\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz7L5PDtOOBN"
      },
      "source": [
        "## Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHFl7oHOOOBN",
        "outputId": "0a8e74fc-ef2d-4fcc-f893-f3f799e9ed2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiy59tlyOOBO"
      },
      "source": [
        "## Pytorch layer modules for *Conv1D* Network\n",
        "\n",
        "\n",
        "\n",
        "### `Conv1d` layer\n",
        "- `torch.nn.Conv1d(in_channels, out_channels, kernel_size)`\n",
        "\n",
        "### `MaxPool1d` layer\n",
        "- `torch.nn.MaxPool1d(kernel_size, stride=None)`\n",
        "- Parameter `stride` follows `kernel_size`.\n",
        "\n",
        "### `ReLU` layer\n",
        "- `torch.nn.ReLU()`\n",
        "\n",
        "### `Linear` layer\n",
        "- `torch.nn.Linear(in_features, out_features, bias=True)`\n",
        "\n",
        "### `Softmax` layer\n",
        "- `torch.nn.Softmax(dim=None)`\n",
        "- Parameter `dim` is usually set to `1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4QmZvOsOOBP"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Nov  1 14:23:31 2018\n",
        "@author: tshzzz\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def conv_dw(inplane,outplane,stride=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inplane,inplane,kernel_size = 3,groups = inplane,stride=stride,padding=1),\n",
        "        nn.BatchNorm2d(inplane),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(inplane,outplane,kernel_size = 1,groups = 1,stride=1),\n",
        "        nn.BatchNorm2d(outplane),\n",
        "        nn.ReLU()    \n",
        "        )\n",
        "\n",
        "def conv_bw(inplane,outplane,kernel_size = 3,stride=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inplane,outplane,kernel_size = kernel_size,groups = 1,stride=stride,padding=1),\n",
        "        nn.BatchNorm2d(outplane),\n",
        "        nn.ReLU() \n",
        "        )\n",
        "\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,num_class=10):\n",
        "        super(MobileNet,self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        layers.append(conv_bw(3,32,3,1))\n",
        "        layers.append(conv_dw(32,64,1))\n",
        "        layers.append(conv_dw(64,128,2))\n",
        "        layers.append(conv_dw(128,128,1))\n",
        "        layers.append(conv_dw(128,256,2))\n",
        "        layers.append(conv_dw(256,256,1))\n",
        "        layers.append(conv_dw(256,512,2))\n",
        "\n",
        "        for i in range(5):\n",
        "            layers.append(conv_dw(512,512,1))\n",
        "        layers.append(conv_dw(512,1024,2))\n",
        "        layers.append(conv_dw(1024,1024,1))\n",
        "\n",
        "        self.classifer = nn.Sequential(\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(1024,num_class)\n",
        "                )\n",
        "        self.feature = nn.Sequential(*layers)\n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.feature(x)\n",
        "        out = out.mean(3).mean(2)\n",
        "        out = out.view(-1,1024)\n",
        "        out = self.classifer(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfzmIU7TOOBQ",
        "outputId": "68d76813-42d3-47ed-bf49-4e7c5f2e717d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MobileNet(\n",
              "  (classifer): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              "  (feature): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
              "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mobile_net = MobileNet()\n",
        "mobile_net.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA56_nXQOOBR"
      },
      "source": [
        "## variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTgBZ03IOOBR"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "clientsoclist = [0]*users\n",
        "\n",
        "start_time = 0\n",
        "weight_count = 0\n",
        "\n",
        "global_weights = copy.deepcopy(mobile_net.state_dict())\n",
        "\n",
        "datasetsize = [0]*users\n",
        "weights_list = [0]*users\n",
        "\n",
        "lock = Lock()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nizwZZltOOBS"
      },
      "source": [
        "## Comunication overhead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lszk9hb0OOBS"
      },
      "outputs": [],
      "source": [
        "total_sendsize_list = []\n",
        "total_receivesize_list = []\n",
        "\n",
        "client_sendsize_list = [[] for i in range(users)]\n",
        "client_receivesize_list = [[] for i in range(users)]\n",
        "\n",
        "train_sendsize_list = [] \n",
        "train_receivesize_list = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZdF0QmcOOBS"
      },
      "source": [
        "## Socket initialization\n",
        "### Set host address and port number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU_aa7RaOOBT"
      },
      "source": [
        "### Required socket functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKywB-d3OOBT"
      },
      "outputs": [],
      "source": [
        "def send_msg(sock, msg):\n",
        "    # prefix each message with a 4-byte length in network byte order\n",
        "    msg = pickle.dumps(msg)\n",
        "    l_send = len(msg)\n",
        "    msg = struct.pack('>I', l_send) + msg\n",
        "    sock.sendall(msg)\n",
        "    return l_send\n",
        "\n",
        "def recv_msg(sock):\n",
        "    # read message length and unpack it into an integer\n",
        "    raw_msglen = recvall(sock, 4)\n",
        "    if not raw_msglen:\n",
        "        return None\n",
        "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
        "    # read the message data\n",
        "    msg =  recvall(sock, msglen)\n",
        "    msg = pickle.loads(msg)\n",
        "    return msg, msglen\n",
        "\n",
        "def recvall(sock, n):\n",
        "    # helper function to receive n bytes or return None if EOF is hit\n",
        "    data = b''\n",
        "    while len(data) < n:\n",
        "        packet = sock.recv(n - len(data))\n",
        "        if not packet:\n",
        "            return None\n",
        "        data += packet\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1cCMmPhOOBT"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def average_weights(w, datasize):\n",
        "    \"\"\"\n",
        "    Returns the average of the weights.\n",
        "    \"\"\"\n",
        "        \n",
        "    for i, data in enumerate(datasize):\n",
        "        for key in w[i].keys():\n",
        "            w[i][key] *= float(data)\n",
        "    \n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    \n",
        "    \n",
        "\n",
        "# when client use only one kinds of device\n",
        "\n",
        "    for key in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[key] += w[i][key]\n",
        "        w_avg[key] = torch.div(w_avg[key], float(sum(datasize)))\n",
        "\n",
        "# when client use various devices (cpu, gpu) you need to use it instead\n",
        "#\n",
        "#     for key, val in w_avg.items():\n",
        "#         common_device = val.device\n",
        "#         break\n",
        "#     for key in w_avg.keys():\n",
        "#         for i in range(1, len(w)):\n",
        "#             if common_device == 'cpu':\n",
        "#                 w_avg[key] += w[i][key].cpu()\n",
        "#             else:\n",
        "#                 w_avg[key] += w[i][key].cuda()\n",
        "#         w_avg[key] = torch.div(w_avg[key], float(sum(datasize)))\n",
        "\n",
        "    return w_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_PrNuFqOOBU"
      },
      "source": [
        "## Thread define"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ufJtUFOOBU"
      },
      "source": [
        "## Receive users before training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-TnYIcvOOBU"
      },
      "outputs": [],
      "source": [
        "def run_thread(func, num_user):\n",
        "    global clientsoclist\n",
        "    global start_time\n",
        "    \n",
        "    thrs = []\n",
        "    for i in range(num_user):\n",
        "        conn, addr = s.accept()\n",
        "        print('Conntected with', addr)\n",
        "        # append client socket on list\n",
        "        clientsoclist[i] = conn\n",
        "        args = (i, num_user, conn)\n",
        "        thread = Thread(target=func, args=args)\n",
        "        thrs.append(thread)\n",
        "        thread.start()\n",
        "    print(\"timmer start!\")\n",
        "    start_time = time.time()    # store start time\n",
        "    for thread in thrs:\n",
        "        thread.join()\n",
        "    end_time = time.time()  # store end time\n",
        "    print(\"TrainingTime: {} sec\".format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm2KH06uOOBV"
      },
      "outputs": [],
      "source": [
        "def receive(userid, num_users, conn): #thread for receive clients\n",
        "    global weight_count\n",
        "    \n",
        "    global datasetsize\n",
        "\n",
        "\n",
        "    msg = {\n",
        "        'rounds': rounds,\n",
        "        'client_id': userid,\n",
        "        'local_epoch': local_epoch\n",
        "    }\n",
        "\n",
        "    datasize = send_msg(conn, msg)    #send epoch\n",
        "    total_sendsize_list.append(datasize)\n",
        "    client_sendsize_list[userid].append(datasize)\n",
        "\n",
        "    train_dataset_size, datasize = recv_msg(conn)    # get total_batch of train dataset\n",
        "    total_receivesize_list.append(datasize)\n",
        "    client_receivesize_list[userid].append(datasize)\n",
        "    \n",
        "    \n",
        "    with lock:\n",
        "        datasetsize[userid] = train_dataset_size\n",
        "        weight_count += 1\n",
        "    \n",
        "    train(userid, train_dataset_size, num_users, conn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJKK107YOOBW"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOi3OxKhOOBW"
      },
      "outputs": [],
      "source": [
        "def train(userid, train_dataset_size, num_users, client_conn):\n",
        "    global weights_list\n",
        "    global global_weights\n",
        "    global weight_count\n",
        "    global mobile_net\n",
        "    global val_acc\n",
        "    \n",
        "    for r in range(rounds):\n",
        "        with lock:\n",
        "            if weight_count == num_users:\n",
        "                for i, conn in enumerate(clientsoclist):\n",
        "                    datasize = send_msg(conn, global_weights)\n",
        "                    total_sendsize_list.append(datasize)\n",
        "                    client_sendsize_list[i].append(datasize)\n",
        "                    train_sendsize_list.append(datasize)\n",
        "                    weight_count = 0\n",
        "\n",
        "        client_weights, datasize = recv_msg(client_conn)\n",
        "        total_receivesize_list.append(datasize)\n",
        "        client_receivesize_list[userid].append(datasize)\n",
        "        train_receivesize_list.append(datasize)\n",
        "\n",
        "        weights_list[userid] = client_weights\n",
        "        print(\"User\" + str(userid) + \"'s Round \" + str(r + 1) +  \" is done\")\n",
        "        with lock:\n",
        "            weight_count += 1\n",
        "            if weight_count == num_users:\n",
        "                #average\n",
        "                global_weights = average_weights(weights_list, datasetsize)\n",
        "                \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdynjV2YOOBY",
        "outputId": "05c0d3bc-e533-40d9-cf9f-b3f48dd69c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "192.168.83.1\n"
          ]
        }
      ],
      "source": [
        "host = socket.gethostbyname(socket.gethostname())\n",
        "port = 10080\n",
        "print(host)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWyan0N2OOBY"
      },
      "outputs": [],
      "source": [
        "s = socket.socket()\n",
        "s.bind((host, port))\n",
        "s.listen(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uSAkgreOOBY"
      },
      "source": [
        "### Open the server socket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yk2HWw9OOBY",
        "outputId": "2d30f3cf-2715-49e8-ec07-1daac28e629a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conntected with ('192.168.83.1', 5808)\n",
            "timmer start!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User0's Round 1 is done\n",
            "TrainingTime: 12.060287475585938 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-6:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-11-86c8b857c02f>\", line 26, in receive\n",
            "    train(userid, train_dataset_size, num_users, conn)\n",
            "  File \"<ipython-input-12-98f4f091f7fc>\", line 29, in train\n",
            "    global_weights = average_weights(weights_list, datasetsize)\n",
            "  File \"<ipython-input-9-c28abdcbbc9a>\", line 10, in average_weights\n",
            "    w[i][key] *= float(data)\n",
            "RuntimeError: result type Float can't be cast to the desired output type Long\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run_thread(receive, users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtaZzlu9OOBZ",
        "outputId": "3b4264fb-0931-4b85-baf5-55efff63f20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainingTime: 12.06924557685852 sec\n"
          ]
        }
      ],
      "source": [
        "end_time = time.time()  # store end time\n",
        "print(\"TrainingTime: {} sec\".format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3HjCnKmOOBZ"
      },
      "source": [
        "## Print all of communication overhead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwc1AfGEOOBZ",
        "outputId": "6a976857-d02a-42b0-93d5-ee373788cedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "---total_sendsize_list---\n",
            "total_sendsize size: 13069937 bytes\n",
            "number of total_send:  2\n",
            "\n",
            "\n",
            "---total_receivesize_list---\n",
            "total receive sizes: 13069881 bytes\n",
            "number of total receive:  2\n",
            "\n",
            "\n",
            "---client_sendsize_list(user0)---\n",
            "total client_sendsizes(user0): 13069937 bytes\n",
            "number of client_send(user0):  2\n",
            "\n",
            "\n",
            "---client_receivesize_list(user0)---\n",
            "total client_receive sizes(user0): 13069881 bytes\n",
            "number of client_send(user0):  2\n",
            "\n",
            "\n",
            "---train_sendsize_list---\n",
            "total train_sendsizes: 13069876 bytes\n",
            "number of train_send:  1\n",
            "\n",
            "\n",
            "---train_receivesize_list---\n",
            "total train_receivesizes: 13069876 bytes\n",
            "number of train_receive:  1\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# def commmunication_overhead():  \n",
        "print('\\n')\n",
        "print('---total_sendsize_list---')\n",
        "total_size = 0\n",
        "for size in total_sendsize_list:\n",
        "#     print(size)\n",
        "    total_size += size\n",
        "print(\"total_sendsize size: {} bytes\".format(total_size))\n",
        "print(\"number of total_send: \", len(total_sendsize_list))\n",
        "print('\\n')\n",
        "\n",
        "print('---total_receivesize_list---')\n",
        "total_size = 0\n",
        "for size in total_receivesize_list:\n",
        "#     print(size)\n",
        "    total_size += size\n",
        "print(\"total receive sizes: {} bytes\".format(total_size) )\n",
        "print(\"number of total receive: \", len(total_receivesize_list) )\n",
        "print('\\n')\n",
        "\n",
        "for i in range(users):\n",
        "    print('---client_sendsize_list(user{})---'.format(i))\n",
        "    total_size = 0\n",
        "    for size in client_sendsize_list[i]:\n",
        "#         print(size)\n",
        "        total_size += size\n",
        "    print(\"total client_sendsizes(user{}): {} bytes\".format(i, total_size))\n",
        "    print(\"number of client_send(user{}): \".format(i), len(client_sendsize_list[i]))\n",
        "    print('\\n')\n",
        "\n",
        "    print('---client_receivesize_list(user{})---'.format(i))\n",
        "    total_size = 0\n",
        "    for size in client_receivesize_list[i]:\n",
        "#         print(size)\n",
        "        total_size += size\n",
        "    print(\"total client_receive sizes(user{}): {} bytes\".format(i, total_size))\n",
        "    print(\"number of client_send(user{}): \".format(i), len(client_receivesize_list[i]))\n",
        "    print('\\n')\n",
        "\n",
        "print('---train_sendsize_list---')\n",
        "total_size = 0\n",
        "for size in train_sendsize_list:\n",
        "#     print(size)\n",
        "    total_size += size\n",
        "print(\"total train_sendsizes: {} bytes\".format(total_size))\n",
        "print(\"number of train_send: \", len(train_sendsize_list) )\n",
        "print('\\n')\n",
        "\n",
        "print('---train_receivesize_list---')\n",
        "total_size = 0\n",
        "for size in train_receivesize_list:\n",
        "#     print(size)\n",
        "    total_size += size\n",
        "print(\"total train_receivesizes: {} bytes\".format(total_size))\n",
        "print(\"number of train_receive: \", len(train_receivesize_list) )\n",
        "print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzAJTqoTOOBa"
      },
      "outputs": [],
      "source": [
        "root_path = '../../models/cifar10_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8jABJ_FOOBa"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdUKOgyHOOBa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcBqkggfOOBa"
      },
      "source": [
        "## Making Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgGEgInkOOBa",
        "outputId": "e436809d-3d3f-4c0c-9778-1597204f288d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10 (root=root_path, train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10 (root=root_path, train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS1u6ILvOOBb"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxlVWwklOOBb"
      },
      "source": [
        "### `DataLoader` for batch generating\n",
        "`torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ClHZ6fEOOBb"
      },
      "source": [
        "### Number of total batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne7nU-rmOOBc",
        "outputId": "34a6fbb0-6806-4168-863d-c2bf804605fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12500\n",
            "2500\n"
          ]
        }
      ],
      "source": [
        "train_total_batch = len(trainloader)\n",
        "print(train_total_batch)\n",
        "test_batch = len(testloader)\n",
        "print(test_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnkJI7kFOOBc"
      },
      "outputs": [],
      "source": [
        "mobile_net.load_state_dict(global_weights)\n",
        "mobile_net.eval()\n",
        "mobile_net = mobile_net.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = optim.SGD(mobile_net.parameters(), lr=lr, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF3VvTUKOOBc"
      },
      "source": [
        "## Accuracy of train and each of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-HwIuY6OOBd",
        "outputId": "86baa5a1-34f9-4e37-df6a-07b4a620976c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc: 10.00%, train_loss: 2.3031\n",
            "test_acc: 10.00%, test_loss: 2.3031\n",
            "Accuracy of plane :  0 %\n",
            "Accuracy of   car :  0 %\n",
            "Accuracy of  bird :  0 %\n",
            "Accuracy of   cat : 100 %\n",
            "Accuracy of  deer :  0 %\n",
            "Accuracy of   dog :  0 %\n",
            "Accuracy of  frog :  0 %\n",
            "Accuracy of horse :  0 %\n",
            "Accuracy of  ship :  0 %\n",
            "Accuracy of truck :  0 %\n",
            "WorkingTime: 737.2920582294464 sec\n"
          ]
        }
      ],
      "source": [
        "# train acc\n",
        "with torch.no_grad():\n",
        "    corr_num = 0\n",
        "    total_num = 0\n",
        "    train_loss = 0.0\n",
        "    for j, trn in enumerate(trainloader):\n",
        "        trn_x, trn_label = trn\n",
        "        trn_x = trn_x.to(device)\n",
        "        trn_label = trn_label.clone().detach().long().to(device)\n",
        "\n",
        "        trn_output = mobile_net(trn_x)\n",
        "        loss = criterion(trn_output, trn_label)\n",
        "        train_loss += loss.item()\n",
        "        model_label = trn_output.argmax(dim=1)\n",
        "        corr = trn_label[trn_label == model_label].size(0)\n",
        "        corr_num += corr\n",
        "        total_num += trn_label.size(0)\n",
        "    print(\"train_acc: {:.2f}%, train_loss: {:.4f}\".format(corr_num / total_num * 100, train_loss / len(trainloader)))\n",
        "\n",
        "\n",
        "# test acc\n",
        "with torch.no_grad():\n",
        "    corr_num = 0\n",
        "    total_num = 0\n",
        "    val_loss = 0.0\n",
        "    for j, val in enumerate(testloader):\n",
        "        val_x, val_label = val\n",
        "        val_x = val_x.to(device)\n",
        "        val_label = val_label.clone().detach().long().to(device)\n",
        "\n",
        "        val_output = mobile_net(val_x)\n",
        "        loss = criterion(val_output, val_label)\n",
        "        val_loss += loss.item()\n",
        "        model_label = val_output.argmax(dim=1)\n",
        "        corr = val_label[val_label == model_label].size(0)\n",
        "        corr_num += corr\n",
        "        total_num += val_label.size(0)\n",
        "        accuracy = corr_num / total_num * 100\n",
        "        test_loss = val_loss / len(testloader)\n",
        "    print(\"test_acc: {:.2f}%, test_loss: {:.4f}\".format( accuracy, test_loss))\n",
        "\n",
        "# acc of each acc    \n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        x, labels = data\n",
        "        x = x.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = mobile_net(x)\n",
        "        labels = labels.long()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "# Let's quickly save our trained model:\n",
        "PATH = './cifar10_fd_mobile.pth'\n",
        "torch.save(mobile_net.state_dict(), PATH)\n",
        "\n",
        "end_time = time.time()  # store end time\n",
        "print(\"WorkingTime: {} sec\".format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klS8ASILOOBd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}